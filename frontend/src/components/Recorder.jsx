import React, { useState, useRef, useEffect } from 'react';
import { Mic, Square, Download, FileText, Loader2 } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';
import toast, { Toaster } from 'react-hot-toast';

// API ì—”ë“œí¬ì¸íŠ¸ ìƒìˆ˜
const API_BASE_URL = import.meta.env.VITE_API_BASE_URL || 'http://localhost:8000/api';
const API_ENDPOINTS = {
    GET_TOKEN: `${API_BASE_URL}/get-token`,
    TRANSCRIBE: `${API_BASE_URL}/transcribe-with-speakers`,
};

// í™”ì ìƒ‰ìƒ íŒ”ë ˆíŠ¸
const SPEAKER_COLORS = [
    'text-blue-400',
    'text-green-400',
    'text-yellow-400',
    'text-pink-400',
    'text-purple-400'
];

const Recorder = () => {
    // --- ìƒíƒœ ê´€ë¦¬ (State Management) ---
    const [isRecording, setIsRecording] = useState(false);          // ë…¹ìŒ ì¤‘ ì—¬ë¶€
    const [transcript, setTranscript] = useState('');               // í™•ì •ëœ í…ìŠ¤íŠ¸ (Committed)
    const [partialTranscript, setPartialTranscript] = useState(''); // ì‹¤ì‹œê°„ ì¸ì‹ ì¤‘ì¸ í…ìŠ¤íŠ¸ (Partial)
    const [status, setStatus] = useState('idle');                   // ìƒíƒœ: idle(ëŒ€ê¸°), connecting(ì—°ê²°ì¤‘), recording(ë…¹ìŒì¤‘), error(ì˜¤ë¥˜)
    const [error, setError] = useState(null);                       // ì—ëŸ¬ ë©”ì‹œì§€
    const [hasAudio, setHasAudio] = useState(false);                // ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ê°€ëŠ¥ ì—¬ë¶€
    const [speakerTranscripts, setSpeakerTranscripts] = useState([]); // í™”ìë³„ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸
    const [isProcessingSpeakers, setIsProcessingSpeakers] = useState(false); // í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì¤‘
    const [audioUrl, setAudioUrl] = useState(null); // ë…¹ìŒëœ ì˜¤ë””ì˜¤ URL

    // --- Refs (ì°¸ì¡° ë³€ìˆ˜) ---
    const mediaRecorderRef = useRef(null);       // íŒŒì¼ ì €ì¥ì„ ìœ„í•œ MediaRecorder
    const socketRef = useRef(null);              // ElevenLabs APIì™€ì˜ WebSocket ì—°ê²°
    const audioChunksRef = useRef([]);           // ì €ì¥í•  ì˜¤ë””ì˜¤ ë°ì´í„° ì²­í¬ ëª¨ìŒ
    const partialTranscriptRef = useRef('');     // ë…¹ìŒ ì¢…ë£Œ ì‹œ ë§ˆì§€ë§‰ ë¶€ë¶„ í…ìŠ¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì°¸ì¡°
    const audioRef = useRef(null);               // ì˜¤ë””ì˜¤ ì¬ìƒì„ ìœ„í•œ ì°¸ì¡°

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    useEffect(() => {
        return () => {
            stopRecording();
            // ì˜¤ë””ì˜¤ URL ë©”ëª¨ë¦¬ í•´ì œ
            if (audioUrl) {
                URL.revokeObjectURL(audioUrl);
            }
        };
    }, [audioUrl]);

    // --- ë…¹ìŒ ì‹œì‘ (Start Recording) ---
    const startRecording = async () => {
        // ì´ì „ ì˜¤ë””ì˜¤ URL ì •ë¦¬
        if (audioUrl) {
            URL.revokeObjectURL(audioUrl);
            setAudioUrl(null);
        }

        setError(null);
        setStatus('connecting');
        setTranscript('');
        setPartialTranscript('');
        setSpeakerTranscripts([]);
        setHasAudio(false);
        partialTranscriptRef.current = '';
        audioChunksRef.current = [];

        try {
            // 1. ë°±ì—”ë“œì—ì„œ ì¸ì¦ í† í° ë°›ì•„ì˜¤ê¸° (Python FastAPI ì„œë²„: 8000ë²ˆ í¬íŠ¸)
            const tokenRes = await fetch(API_ENDPOINTS.GET_TOKEN);
            if (!tokenRes.ok) {
                throw new Error('ë°±ì—”ë“œì—ì„œ í† í°ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
            }
            const { token } = await tokenRes.json();

            // 2. ElevenLabs Realtime API WebSocket ì—°ê²°
            // model_id: scribe_v2 (ê¸°ë³¸ê°’ ì‚¬ìš©)
            const wsUrl = `wss://api.elevenlabs.io/v1/speech-to-text/realtime?token=${token}`;
            const socket = new WebSocket(wsUrl);

            socket.onopen = () => {
                console.log('ElevenLabs WebSocket ì—°ê²° ì„±ê³µ');
                setStatus('recording');
                setIsRecording(true);
                // WebSocketì´ ì—°ê²°ë˜ë©´ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œì‘
                startMediaRecorder(socket);
            };

            socket.onmessage = (event) => {
                const data = JSON.parse(event.data);

                // ë©”ì‹œì§€ íƒ€ì… í™•ì¸ (partial_transcript: ì§„í–‰ ì¤‘, committed_transcript: í™•ì •ë¨)
                const msgType = data.message_type || data.type;

                if (msgType === 'partial_transcript') {
                    setPartialTranscript(data.text);
                    partialTranscriptRef.current = data.text;
                } else if (msgType === 'committed_transcript') {
                    // í™•ì •ëœ í…ìŠ¤íŠ¸ëŠ” ê¸°ì¡´ í…ìŠ¤íŠ¸ ë’¤ì— ì´ì–´ ë¶™ì„
                    setTranscript((prev) => prev + ' ' + data.text);
                    setPartialTranscript('');
                    partialTranscriptRef.current = '';
                }
            };

            socket.onerror = (err) => {
                console.error('WebSocket ì˜¤ë¥˜:', err);
                setError('WebSocket ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
                stopRecording();
            };

            socket.onclose = (event) => {
                console.log(`WebSocket ì—°ê²° ì¢…ë£Œ. ì½”ë“œ: ${event.code}`);
                setIsRecording(false);
                setStatus('idle');
            };

            socketRef.current = socket;

        } catch (err) {
            console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', err);
            setError(err.message);
            setStatus('idle');
        }
    };

    // --- ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ (Audio Processing) ---
    const startMediaRecorder = async (socket) => {
        try {
            // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            // 1. ì‹¤ì‹œê°„ ì „ì†¡ìš© AudioContext ì„¤ì • (16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ í•„ìˆ˜)
            const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
            await audioContext.resume();

            const source = audioContext.createMediaStreamSource(stream);
            let processor = null;
            let workletNode = null;

            // AudioWorklet ì§€ì› í™•ì¸ ë° ì‚¬ìš©
            if (audioContext.audioWorklet) {
                try {
                    await audioContext.audioWorklet.addModule('/audio-processor.worklet.js');
                    workletNode = new AudioWorkletNode(audioContext, 'audio-processor');

                    // AudioWorkletì—ì„œ ì˜¤ëŠ” ë©”ì‹œì§€ ì²˜ë¦¬
                    workletNode.port.onmessage = (event) => {
                        if (event.data.type === 'audioData') {
                            const pcmData = event.data.data;

                            // Base64 ì¸ì½”ë”©
                            const base64Audio = btoa(
                                String.fromCharCode(...new Uint8Array(pcmData.buffer))
                            );

                            // WebSocketì´ ì—´ë ¤ìˆì„ ë•Œë§Œ ë°ì´í„° ì „ì†¡
                            if (socket.readyState === WebSocket.OPEN) {
                                socket.send(JSON.stringify({
                                    message_type: 'input_audio_chunk',
                                    audio_base_64: base64Audio,
                                    sample_rate: 16000
                                }));
                            }
                        }
                    };

                    source.connect(workletNode);
                    workletNode.connect(audioContext.destination);
                    console.log('âœ… AudioWorklet ì‚¬ìš© ì¤‘');

                } catch (workletError) {
                    console.warn('âš ï¸ AudioWorklet ë¡œë“œ ì‹¤íŒ¨, ScriptProcessorNodeë¡œ fallback:', workletError);
                    workletNode = null;
                }
            }

            // AudioWorkletì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë©´ ScriptProcessorNode ì‚¬ìš© (fallback)
            if (!workletNode) {
                console.log('ğŸ“¢ ScriptProcessorNode ì‚¬ìš© ì¤‘ (deprecated)');
                processor = audioContext.createScriptProcessor(4096, 1, 1);

                source.connect(processor);
                processor.connect(audioContext.destination);

                processor.onaudioprocess = (e) => {
                    const inputData = e.inputBuffer.getChannelData(0);

                    // Float32 ë°ì´í„°ë¥¼ 16-bit PCM ì •ìˆ˜ë¡œ ë³€í™˜ (ElevenLabs API ìš”êµ¬ì‚¬í•­)
                    const pcmData = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const s = Math.max(-1, Math.min(1, inputData[i]));
                        pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }

                    // Base64 ì¸ì½”ë”©
                    const base64Audio = btoa(
                        String.fromCharCode(...new Uint8Array(pcmData.buffer))
                    );

                    // WebSocketì´ ì—´ë ¤ìˆì„ ë•Œë§Œ ë°ì´í„° ì „ì†¡
                    if (socket.readyState === WebSocket.OPEN) {
                        socket.send(JSON.stringify({
                            message_type: 'input_audio_chunk',
                            audio_base_64: base64Audio,
                            sample_rate: 16000
                        }));
                    }
                };
            }

            // 2. íŒŒì¼ ì €ì¥ìš© MediaRecorder ì„¤ì • (ë¸Œë¼ìš°ì € ê¸°ë³¸ í¬ë§·, ë³´í†µ WebM)
            const mediaRecorder = new MediaRecorder(stream);

            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    audioChunksRef.current.push(event.data);
                    setHasAudio(true); // ë°ì´í„°ê°€ ìŒ“ì´ë©´ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í™œì„±í™”
                }
            };

            // ë…¹ìŒ ì¤‘ì§€ ì‹œ í™”ì ë¶„ë¦¬ ì²˜ë¦¬
            mediaRecorder.onstop = () => {
                console.log('ğŸ“¼ MediaRecorder ì¤‘ì§€ë¨, í™”ì ë¶„ë¦¬ ì‹œì‘...');
                // ë…¹ìŒì´ ì™„ì „íˆ ì¤‘ì§€ëœ í›„ í™”ì ë¶„ë¦¬ ì²˜ë¦¬
                setTimeout(() => {
                    processSpeakerDiarization();
                }, 100);
            };

            mediaRecorder.start();

            // ë‚˜ì¤‘ì— ì •ë¦¬ë¥¼ ìœ„í•´ ì°¸ì¡° ì €ì¥
            mediaRecorderRef.current = {
                stop: () => {
                    // AudioContext ë¦¬ì†ŒìŠ¤ ì •ë¦¬
                    if (workletNode) {
                        workletNode.disconnect();
                        workletNode.port.close();
                    }
                    if (processor) {
                        processor.disconnect();
                    }
                    source.disconnect();
                    audioContext.close();

                    // MediaRecorder ì¤‘ì§€
                    if (mediaRecorder.state !== 'inactive') {
                        mediaRecorder.stop();
                    }

                    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ ì¤‘ì§€ (ë§ˆì´í¬ ì•„ì´ì½˜ êº¼ì§)
                    stream.getTracks().forEach(track => track.stop());
                }
            };

        } catch (err) {
            console.error('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', err);
            setError('ë§ˆì´í¬ ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.');
            stopRecording();
        }
    };

    // --- ë…¹ìŒ ì¤‘ì§€ (Stop Recording) ---
    const stopRecording = () => {
        // ë¯¸ë””ì–´ ë ˆì½”ë” ë° ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬
        if (mediaRecorderRef.current) {
            mediaRecorderRef.current.stop();
        }
        // WebSocket ì—°ê²° ì¢…ë£Œ
        if (socketRef.current) {
            socketRef.current.close();
        }

        // ì•„ì§ í™•ì •ë˜ì§€ ì•Šì€ ë¶€ë¶„ í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ê²°ê³¼ì— ì¶”ê°€
        if (partialTranscriptRef.current) {
            setTranscript((prev) => prev + ' ' + partialTranscriptRef.current);
            setPartialTranscript('');
            partialTranscriptRef.current = '';
        }

        setIsRecording(false);
        setStatus('idle');

        // í™”ì ë¶„ë¦¬ëŠ” mediaRecorder.onstop ì´ë²¤íŠ¸ì—ì„œ ì²˜ë¦¬ë¨
    };

    // --- í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ---
    const processSpeakerDiarization = async () => {
        if (audioChunksRef.current.length === 0) {
            console.log('âš ï¸ ì˜¤ë””ì˜¤ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤. í™”ì ë¶„ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.');
            return;
        }

        console.log('ğŸ¤ í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì‹œì‘...');
        setIsProcessingSpeakers(true);
        setStatus('processing');

        try {
            // ì˜¤ë””ì˜¤ Blob ìƒì„±
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
            console.log(`ğŸ“¦ ì˜¤ë””ì˜¤ Blob í¬ê¸°: ${audioBlob.size} bytes`);

            // FormData ìƒì„±
            const formData = new FormData();
            formData.append('audio', audioBlob, 'recording.webm');

            console.log('ğŸ“¤ ë°±ì—”ë“œë¡œ ìš”ì²­ ì „ì†¡ ì¤‘...');
            // ë°±ì—”ë“œë¡œ ì „ì†¡
            const response = await fetch(API_ENDPOINTS.TRANSCRIBE, {
                method: 'POST',
                body: formData
            });

            console.log(`ğŸ“¥ ì‘ë‹µ ìƒíƒœ: ${response.status} ${response.statusText}`);

            if (!response.ok) {
                const errorText = await response.text();
                console.error('âŒ API ì˜¤ë¥˜ ì‘ë‹µ:', errorText);

                // ìƒíƒœ ì½”ë“œì— ë”°ë¥¸ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€
                let userMessage = 'í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
                try {
                    const errorData = JSON.parse(errorText);
                    userMessage = errorData.detail || userMessage;
                } catch (e) {
                    // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©
                }

                throw new Error(userMessage);
            }

            const data = await response.json();
            console.log('âœ… API ì‘ë‹µ ë°ì´í„°:', data);

            if (data.success && data.speakers) {
                console.log(`ğŸ‘¥ í™”ì ìˆ˜: ${data.speakers.length}`);
                data.speakers.forEach((speaker, i) => {
                    console.log(`  í™”ì ${i+1}: ${speaker.speaker} - "${speaker.text.substring(0, 50)}..."`);
                });
                setSpeakerTranscripts(data.speakers);

                // ì˜¤ë””ì˜¤ URL ìƒì„± ë° ì €ì¥
                const url = URL.createObjectURL(audioBlob);
                setAudioUrl(url);
                console.log('ğŸµ ì˜¤ë””ì˜¤ URL ìƒì„± ì™„ë£Œ');
            } else {
                console.warn('âš ï¸ í™”ì ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤:', data);
                setError('í™”ì ë¶„ë¦¬ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
            }

        } catch (err) {
            console.error('âŒ í™”ì ë¶„ë¦¬ ì˜¤ë¥˜:', err);
            setError(err.message);
        } finally {
            setIsProcessingSpeakers(false);
            setStatus('idle');
            console.log('ğŸ í™”ì ë¶„ë¦¬ ì²˜ë¦¬ ì¢…ë£Œ');
        }
    };

    // --- í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ---
    const downloadTxt = () => {
        let textToSave = '';

        // í™”ì ë¶„ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë©´ í™”ìë³„ í…ìŠ¤íŠ¸ë¥¼ í™”ì êµ¬ë¶„ ì—†ì´ ìˆœì„œëŒ€ë¡œ ì €ì¥
        if (speakerTranscripts.length > 0) {
            textToSave = speakerTranscripts
                .map(item => item.text.trim())  // ê° í…ìŠ¤íŠ¸ì˜ ì•ë’¤ ê³µë°± ì œê±°
                .join(' ')  // ê³µë°±ìœ¼ë¡œ ì´ì–´ë¶™ì„
                .replace(/\s+/g, ' ');  // ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¹˜í™˜
        } else {
            // í™”ì ë¶„ë¦¬ê°€ ì—†ìœ¼ë©´ ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ì €ì¥
            textToSave = (transcript + (partialTranscript ? ' ' + partialTranscript : ''))
                .replace(/\s+/g, ' ');  // ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¹˜í™˜
        }

        if (!textToSave.trim()) {
            toast.error("ì €ì¥í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.");
            return;
        }

        downloadFile(textToSave.trim(), 'transcription.txt');
        toast.success("í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.");
    };

    // --- íŒŒì¼ ë‹¤ìš´ë¡œë“œ ê³µí†µ í•¨ìˆ˜ ---
    const downloadFile = (content, filename, mimeType = 'text/plain;charset=utf-8') => {
        const element = document.createElement("a");
        const file = new Blob([content], { type: mimeType });
        element.href = URL.createObjectURL(file);
        element.download = filename;
        document.body.appendChild(element);
        element.click();
        document.body.removeChild(element);
        URL.revokeObjectURL(element.href);
    };

    // --- ì˜¤ë””ì˜¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ---
    const downloadWav = () => {
        if (audioChunksRef.current.length === 0) {
            toast.error("ì €ì¥í•  ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.");
            return;
        }
        const blob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
        downloadFile(blob, 'recording.webm', 'audio/webm');
        toast.success("ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.");
    };

    // --- í™”ìë³„ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ ---
    const downloadSpeakerTranscripts = () => {
        if (speakerTranscripts.length === 0) {
            toast.error("í™”ìë³„ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.");
            return;
        }

        // í™”ìë³„ë¡œ í¬ë§·íŒ…
        let formattedText = "=== í™”ìë³„ êµ¬ë¶„ëœ ëŒ€í™”ë¡ ===\n\n";

        speakerTranscripts.forEach((item, index) => {
            const speakerLabel = item.speaker || `í™”ì ${index + 1}`;
            const startTime = formatTime(item.start);
            const endTime = formatTime(item.end);

            // í…ìŠ¤íŠ¸ ê³µë°± ì •ë¦¬
            const cleanedText = item.text.trim().replace(/\s+/g, ' ');

            formattedText += `[${speakerLabel}] (${startTime} - ${endTime})\n`;
            formattedText += `${cleanedText}\n\n`;
        });

        downloadFile(formattedText, 'speaker_transcription.txt');
        toast.success("í™”ìë³„ í…ìŠ¤íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.");
    };

    // --- í™”ì í´ë¦­ ì‹œ ì˜¤ë””ì˜¤ ì¬ìƒ ---
    const playFromTimestamp = (startTime) => {
        if (!audioRef.current || !audioUrl) {
            console.warn('âš ï¸ ì˜¤ë””ì˜¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
            return;
        }

        console.log(`â–¶ï¸ ${startTime}ì´ˆë¶€í„° ì¬ìƒ ì‹œì‘`);
        audioRef.current.currentTime = startTime;
        audioRef.current.play().catch(err => {
            console.error('ì¬ìƒ ì˜¤ë¥˜:', err);
            setError('ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
        });
    };

    // --- ì‹œê°„ í¬ë§· í•¨ìˆ˜ ---
    const formatTime = (seconds) => {
        if (!seconds && seconds !== 0) return '00:00';
        const mins = Math.floor(seconds / 60);
        const secs = Math.floor(seconds % 60);
        return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
    };

    return (
        <div className="flex flex-col items-center justify-center min-h-screen bg-gradient-to-br from-gray-900 via-purple-900 to-violet-900 text-white p-4">
            <Toaster
                position="top-center"
                toastOptions={{
                    duration: 3000,
                    style: {
                        background: '#363636',
                        color: '#fff',
                    },
                    success: {
                        iconTheme: {
                            primary: '#10b981',
                            secondary: '#fff',
                        },
                    },
                    error: {
                        iconTheme: {
                            primary: '#ef4444',
                            secondary: '#fff',
                        },
                    },
                }}
            />
            <div className="w-full max-w-2xl bg-white/10 backdrop-blur-lg rounded-3xl p-8 shadow-2xl border border-white/20">

                <div className="text-center mb-8">
                    <h1 className="text-4xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-400 mb-2">
                        Realtime Scribe
                    </h1>
                    <p className="text-gray-400">ElevenLabs Transcription API Demo</p>
                </div>

                {/* ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ í‘œì‹œ ì˜ì—­ */}
                <div className="mb-4">
                    <h3 className="text-sm font-semibold text-gray-400 mb-2">ì‹¤ì‹œê°„ ë³€í™˜</h3>
                    <div className="h-48 overflow-y-auto bg-black/30 rounded-xl p-4 border border-white/10 font-mono text-sm leading-relaxed scrollbar-thin scrollbar-thumb-gray-600 scrollbar-track-transparent">
                        {(transcript || partialTranscript) ? (
                            <>
                                <span className="text-gray-300">{transcript}</span>
                                <span className="text-blue-400 animate-pulse ml-1">{partialTranscript}</span>
                            </>
                        ) : (
                            <div className="h-full flex items-center justify-center text-gray-600 italic">
                                ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”...
                            </div>
                        )}
                    </div>
                </div>

                {/* í™”ìë³„ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ í‘œì‹œ ì˜ì—­ */}
                {speakerTranscripts.length > 0 && (
                    <div className="mb-8">
                        <h3 className="text-sm font-semibold text-gray-400 mb-2 flex items-center gap-2">
                            <span>í™”ìë³„ êµ¬ë¶„</span>
                            {isProcessingSpeakers && (
                                <Loader2 className="w-4 h-4 animate-spin text-blue-400" />
                            )}
                        </h3>
                        <div className="h-64 overflow-y-auto bg-black/30 rounded-xl p-4 border border-white/10 font-mono text-sm leading-relaxed scrollbar-thin scrollbar-thumb-gray-600 scrollbar-track-transparent">
                            {speakerTranscripts.map((item, index) => {
                                const speakerColor = SPEAKER_COLORS[index % SPEAKER_COLORS.length];

                                return (
                                    <div
                                        key={index}
                                        className="mb-4 cursor-pointer hover:bg-white/5 p-2 rounded-lg transition-colors"
                                        onClick={() => playFromTimestamp(item.start)}
                                        title="í´ë¦­í•˜ì—¬ ì´ ë¶€ë¶„ë¶€í„° ì¬ìƒ"
                                    >
                                        <div className="flex items-center gap-2 mb-1">
                                            <span className={`font-bold ${speakerColor}`}>
                                                [{item.speaker || `í™”ì ${index + 1}`}]
                                            </span>
                                            <span className="text-xs text-gray-500">
                                                {formatTime(item.start)} - {formatTime(item.end)}
                                            </span>
                                        </div>
                                        <div className="text-gray-300 pl-4">
                                            {item.text}
                                        </div>
                                    </div>
                                );
                            })}
                        </div>
                    </div>
                )}

                {/* ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ */}
                {audioUrl && (
                    <div className="mb-6">
                        <h3 className="text-sm font-semibold text-gray-400 mb-2">ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´</h3>
                        <audio
                            ref={audioRef}
                            src={audioUrl}
                            controls
                            className="w-full rounded-lg"
                            style={{
                                filter: 'invert(0.9) hue-rotate(180deg)',
                                height: '40px'
                            }}
                        />
                    </div>
                )}

                {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ ì˜ì—­ */}
                <div className="flex flex-col items-center gap-6">

                    {/* ë…¹ìŒ ë²„íŠ¼ */}
                    <motion.button
                        whileHover={{ scale: 1.05 }}
                        whileTap={{ scale: 0.95 }}
                        onClick={isRecording ? stopRecording : startRecording}
                        disabled={status === 'connecting'}
                        className={`
              relative w-20 h-20 rounded-full flex items-center justify-center shadow-lg transition-all duration-300
              ${isRecording
                                ? 'bg-red-500 hover:bg-red-600 shadow-red-500/50'
                                : 'bg-blue-500 hover:bg-blue-600 shadow-blue-500/50'}
              ${status === 'connecting' ? 'opacity-70 cursor-not-allowed' : ''}
            `}
                    >
                        {status === 'connecting' ? (
                            <Loader2 className="w-8 h-8 animate-spin text-white" />
                        ) : isRecording ? (
                            <Square className="w-8 h-8 text-white fill-current" />
                        ) : (
                            <Mic className="w-8 h-8 text-white" />
                        )}

                        {/* ë…¹ìŒ ì¤‘ì¼ ë•Œ í¼ì§€ëŠ” ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼ */}
                        {isRecording && (
                            <span className="absolute inline-flex h-full w-full rounded-full bg-red-400 opacity-75 animate-ping"></span>
                        )}
                    </motion.button>

                    <div className="text-sm font-medium text-gray-300">
                        {status === 'idle' && 'Click to Record'}
                        {status === 'connecting' && 'ì—°ê²° ì¤‘...'}
                        {status === 'recording' && 'ë“£ê³  ìˆìŠµë‹ˆë‹¤...'}
                        {status === 'processing' && 'í™”ì ë¶„ë¦¬ ì¤‘...'}
                        {error && <span className="text-red-400">{error}</span>}
                    </div>

                    {/* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ */}
                    <div className="flex flex-wrap gap-3 mt-4 justify-center">
                        <motion.button
                            whileHover={{ scale: 1.05 }}
                            whileTap={{ scale: 0.95 }}
                            onClick={downloadWav}
                            disabled={!hasAudio}
                            className="flex items-center gap-2 px-4 py-2 bg-white/5 hover:bg-white/10 rounded-lg border border-white/10 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
                        >
                            <Download className="w-4 h-4" />
                            <span>Save Audio</span>
                        </motion.button>

                        <motion.button
                            whileHover={{ scale: 1.05 }}
                            whileTap={{ scale: 0.95 }}
                            onClick={downloadTxt}
                            disabled={!transcript && !partialTranscript && speakerTranscripts.length === 0}
                            className="flex items-center gap-2 px-4 py-2 bg-white/5 hover:bg-white/10 rounded-lg border border-white/10 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
                        >
                            <FileText className="w-4 h-4" />
                            <span>Save Text</span>
                        </motion.button>

                        {speakerTranscripts.length > 0 && (
                            <motion.button
                                whileHover={{ scale: 1.05 }}
                                whileTap={{ scale: 0.95 }}
                                onClick={downloadSpeakerTranscripts}
                                className="flex items-center gap-2 px-4 py-2 bg-gradient-to-r from-blue-500 to-purple-500 hover:from-blue-600 hover:to-purple-600 rounded-lg border border-blue-400/30 transition-colors shadow-lg"
                            >
                                <FileText className="w-4 h-4" />
                                <span>Save Speaker Text</span>
                            </motion.button>
                        )}
                    </div>

                </div>
            </div>
        </div>
    );
};

export default Recorder;
