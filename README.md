# Voice-to-Text 프로젝트

이 저장소는 음성을 텍스트로 변환하는 두 가지 솔루션을 제공합니다.

## 📁 프로젝트 구조

### 1. ElevenLabs Realtime Transcription (루트 디렉토리)
ElevenLabs Scribe v2 Realtime API를 사용한 **실시간 음성 인식** 앱입니다.
- **장점**: 매우 빠른 실시간 처리, 높은 정확도
- **단점**: API 키 필요, 크레딧 소비
- **적합한 경우**: 실시간 스트리밍, 프로덕션 환경

### 2. Whisper Local (whisper-local/)
OpenAI Whisper를 사용한 **완전 로컬** 음성 인식 솔루션입니다.
- **장점**: 무료, API 키 불필요, 완전 프라이빗
- **단점**: 실시간 불가능 (파일 업로드 후 처리), GPU 없으면 느림
- **적합한 경우**: 개발/테스트, 프라이빗 환경, 비용 절감

---

## 🚀 ElevenLabs Realtime Transcription App

ElevenLabs Scribe v2 Realtime API를 사용하여 실시간 받아쓰기 기능을 제공합니다.
PC와 모바일에서 동작하며, 녹음된 내용을 화면에 표시하고 WAV 및 TXT 파일로 저장할 수 있습니다.

## 사전 준비

1.  **ElevenLabs API Key**: [ElevenLabs](https://elevenlabs.io)에서 API 키를 발급받으세요.
2.  **Node.js**: 최신 버전이 설치되어 있어야 합니다.

## 설치 및 실행

### 1. 백엔드 설정 (토큰 발급 서버)

루트 디렉토리에서 다음을 실행합니다.

```bash
# 의존성 설치
npm install

# 환경 변수 설정
cp .env.example .env
# .env 파일을 열고 XI_API_KEY에 API 키를 입력하세요.
```

서버 실행:

```bash
./start.sh # 실행 (백엔드, 프론트엔드 실행)
```
브라우저에서 `http://localhost:5173` (또는 터미널에 표시된 주소)를 엽니다.

## 모바일 테스트

모바일에서 테스트하려면 PC와 모바일이 같은 와이파이에 있어야 합니다.
`npm run dev` 실행 시 표시되는 `Network` 주소(예: `http://192.168.x.x:5173`)로 모바일 브라우저에서 접속하세요.
**주의**: 모바일 브라우저에서 마이크 권한을 허용하려면 HTTPS가 필요할 수 있습니다. 로컬 개발 환경에서는 `vite-plugin-mkcert` 등을 사용하거나, Chrome의 `chrome://flags/#unsafely-treat-insecure-origin-as-secure` 설정을 통해 HTTP 접속을 허용해야 할 수 있습니다.

## 기능

- **실시간 받아쓰기**: 마이크 버튼을 누르면 ElevenLabs API를 통해 실시간으로 텍스트가 변환됩니다.
- **파일 저장**:
    - **Save Audio**: 녹음된 오디오를 WebM(또는 WAV) 형식으로 저장합니다.
    - **Save Text**: 변환된 텍스트를 TXT 파일로 저장합니다.

## 화자별 텍스트 파일 형식

  저장되는 텍스트 파일 예시:
  === 화자별 구분된 대화록 ===

  [화자 1] (00:00 - 00:15)
  안녕하세요. 오늘 회의를 시작하겠습니다.

  [화자 2] (00:16 - 00:30)
  네, 좋습니다. 먼저 첫 번째 안건부터 논의하시죠.

  [화자 1] (00:31 - 00:45)
  첫 번째 안건은 프로젝트 일정입니다.

  🎨 UI 변경사항

  1. 실시간 변환 섹션: 기존 실시간 텍스트
  2. 화자별 구분 섹션: 녹음 종료 후 자동 표시
    - 각 화자 다른 색상 (파랑, 초록, 노랑, 핑크, 보라)
    - 타임스탬프 표시
  3. Save Speaker Text 버튼: 화자 구분 완료 시 나타남

  🔧 작동 방식

  1. 녹음 시작 → Realtime API로 실시간 텍스트 표시
  2. 녹음 중지 → 오디오 파일을 백엔드로 전송
  3. 자동 처리 → Scribe v1 API로 화자 분리
  4. 결과 표시 → 화자별 구분된 텍스트 표시
  5. 다운로드 → 화자별 텍스트 파일 저장

  📊 API 엔드포인트

  새로 추가된 엔드포인트:
  - POST /api/transcribe-with-speakers: 오디오 파일을 받아 화자 분리된 텍스트 반환
    - server.js:60-125

  이제 2명 이상의 화자가 있는 대화를 녹음하면 자동으로 구분되어 표시됩니다! 🎤👥

---
